# 后端-数据处理-v2

主要五个模块：**预处理、模式识别、日志总结、意图预测、能力分析**

向上提供能力：日志总结、意图预测、能力分析

**计划先按这版方案把原型调通了，这版至少知道能怎么编写了，根据实际效果再看哪些位置需要调整/提升复杂度。**

[TOC]

## 预处理

插件前端收集数据时进行简单的合并处理，形成raw_data。在预处理模块进一步处理：

1. **event_type转换**：前端收集的事件类型基于API，能进一步总结
2. **剔除冗余数据**：看数据集情况
3. **形成历史操作件artifact_history**：用于后续的预测检索
4. **形成历史命令cmd_history**：用于后续的预测检索

## 模式识别

根据程序员开发过程中普遍的几种行为类型，初版原型工具设定如下几种固定的模式/状态，状态内的操作都有明显的类型倾向。

这几种模式的切换频率可能较高，打标最好找内部人员，能完全理解我们的行为建模目的。

方案：规则库识别（v1的粗粒度比较好用规则，细化之后不知道行不行，如果不行，再用CFC）

主要是模式需要打标，打标数据相比后面的预测数据量少。

### 配置环境

执行的命令类型多为install、可能出现静态检查问题、操作的文件多为配置文件

1. **安装依赖包**：pip, mvn, conda, npm等
2. **编辑配置文件**：packge.json, requirement.txt, cmakelist.txt, build.gn等
3. **编辑源代码的依赖相关部件**：import, include, 增删部分用到依赖包的地方等

### 调查阅读

鼠标滚轮滑动、选中文本但不编辑、文件跳转、代码符号跳转、搜索事件密集，编辑操作少

1. **单文件阅读代码**：鼠标停留，查看悬停文档，滚轮滑动
2. **跨文件阅读代码**：前面的行为+文件跳转
3. **查找关联部件**：代码符号跳转、文件搜索、全局搜索、文件跳转、查找引用

### 编写内容

一段时间内主要事件都是文本变化

1. **增加**：总体上新增文本内容/新增文件，体现为artifact的增加
2. **修改**：改变代码编排结构/移动重命名文件，比如修改某个func的出入参时，要修改func内逻辑、调用func的artifacts的逻辑，包含了重构行为
3. **减少**：总体上删除文本内容/删除文件，体现为artifact的减少
4. **注释**：增改注释

### 执行验证

频繁执行命令和调试，可能配合少量编辑操作，原因复杂，这种情况可能是在调整运行效果、验证某些功能，也可能是在修复某些问题，直接原因可能来自调试输出或终端也可能不是，因此统称为“验证”

1. **修改代码**：不同于前面的编写，这里来源于执行的结果
2. **阅读代码**：不同于前面的阅读，这里在思考问题原因等
3. **执行命令**：g++, gcc, python, 启动debug调试等

### 中性操作

不明确属于任何一类模式，有可能什么都不做，有可能是以下没有明显意义的操作，**可能穿插在以上所有模式中**：

<u>如果只用规则识别模式，是否通过预处理来去掉这些内容；如果用CFC，那这些操作放在序列中可能有潜在的特征也能利用。</u>

1. **文件开关切换**、**终端开关切换**：这些切换操作在每个模式里都可能出现，可能代表注意力的转移但是注意什么我们不知道
2. **常见终端命令、未知终端命令**：cd/pwd/su等过于常见的命令、规则库之外的终端cmd

## 日志总结

提供日志总结功能，总结程序员最近在干什么事，干的内容是什么，具体包括：

1. **工作模式**：调用模式识别模块
2. **聚焦位置**：程序员当前关注的操作件或命令，来源于artifact_history和cmd_history

| 方案                                    | 输入                   | 输出          |
| --------------------------------------- | ---------------------- | ------------- |
| 聚焦位置直接选用频度最高的artifact和cmd | 预处理过的动作数据序列 | 模式+聚焦位置 |

## 意图预测

预测开发者的意图，具体包括：

1. **工作模式**：调用模式识别模块
2. **操作**：操作对象、命令。

其中后端计算模式，提供artifact_history、cmd_history中的检索结果，然后需要指导前端进一步根据repo内容获取每个工作模式下需要进一步提供的信息(不在操作历史中)。

#### 新旧预测-后端

先尝试简单的神经网络模型，online，增量式学习，实时更新

**每个小模式单独用一个模型**

预测方法：**基于artifact_history维护一个历史库**(时间跨度大于max_seq_len)，每出现一个未知的artifact就打标为new，反之为old，用来实时训练

| 方案           | 输入                                                        | 输出              |
| -------------- | ----------------------------------------------------------- | ----------------- |
| 对artifact预测 | [频度, 与其他artifact的ref距离, 与其他artifact的振荡耦合度] | one-hot[new, old] |

#### 历史检索-后端

规则+检索，先尝试简单的机器学习模型例如逻辑回归，online，增量式学习，实时更新，简单模型可解释，也容易看出输入特征有没有用。

**每个小模式单独用一个模型**

检索方法：

1. 对artifact_history中每个artifact打分
2. cmd_history的有关命令（频度统计+规则匹配）

其中对于输入特征中指标的计算，范围是属于该模式的最近操作历史（模式识别会给到有用的检索范围）

| 方案           | 输入                                                        | 输出 |
| -------------- | ----------------------------------------------------------- | ---- |
| 对artifact检索 | [频度, 与其他artifact的ref距离, 与其他artifact的振荡耦合度] | 分数 |
| 对cmd用规则    | 频度排名+模式相关度过滤                                     |      |

#### 新件检索-前端

| 模式     | 输入               | 输出                                                |
| -------- | ------------------ | --------------------------------------------------- |
| 配置环境 | 模式+检索结果+指导 | 模式+检索结果+仓库的配置文件等(规则匹配)            |
| 调查阅读 | 模式+检索结果+指导 | 模式+检索结果+与检索结果涉及的ref相关artifact       |
| 编写内容 | 模式+检索结果+指导 | 模式+检索结果                                       |
| 执行验证 | 模式+检索结果+指导 | 模式+检索结果+traceback中提到的有关操作件(规则匹配) |
| 未知     | 模式+检索结果+指导 | 模式+检索结果+                                      |

## 能力分析

以后再想

